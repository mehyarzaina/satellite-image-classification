{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VcjnTTIw1efS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torchvision.models import VGG16_Weights\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNGPovFqhz0x"
   },
   "outputs": [],
   "source": [
    "pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7gIJdrz1lmA",
    "outputId": "e96aa988-a7d0-4d61-e639-e6e6f9a4f96c"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUddT4t21nb_"
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"archive (8).zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"Satellite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CtGksJoC1puy",
    "outputId": "994567f6-a42d-42b1-ebbf-7fb2049abfa9"
   },
   "outputs": [],
   "source": [
    "data_directory = pathlib.Path('/content/Satellite')\n",
    "#reverse folder order\n",
    "class_names = [item.name for item in data_directory.glob('*')][:2][::-1]\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORfNwUD01tGp",
    "outputId": "f2346095-ad3c-4c57-96e5-2971496cf98c"
   },
   "outputs": [],
   "source": [
    "data_dir = '/content/Satellite/data'\n",
    "\n",
    "cloudy_img = '/content/Satellite/data/cloudy'\n",
    "desert_img = '/content/Satellite/data/desert'\n",
    "green_area_img = '/content/Satellite/data/green_area'\n",
    "water_img = '/content/Satellite/data/water'\n",
    "\n",
    "print(f'Number of cloudy images:      {len(os.listdir(cloudy_img))}')\n",
    "print(f'Number of desert images:      {len(os.listdir(desert_img))}')\n",
    "print(f'Number of green_area images:  {len(os.listdir(green_area_img))}')\n",
    "print(f'Number of water images:       {len(os.listdir(water_img))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0U1i5Xa1ySO"
   },
   "source": [
    "# **Data Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_m5CzYKZ1tjD"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jmb2GlkB13_u"
   },
   "outputs": [],
   "source": [
    "data = ImageFolder(data_dir, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "upFYSoPd14cS",
    "outputId": "65d319c4-ee1e-4762-b183-9357f9c1639b"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_len = int(0.80 * len(data))\n",
    "val_len   = int(0.10 * len(data))\n",
    "test_len  = len(data) - train_len - val_len\n",
    "print(train_len,val_len,test_len)\n",
    "\n",
    "generator = torch.Generator().manual_seed(RANDOM_SEED)\n",
    "train_data, val_data, test_data = random_split(data, [train_len, val_len, test_len], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECFa3-713Tqt"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset, Subset\n",
    "import copy\n",
    "\n",
    "augmentation_factor = 4\n",
    "\n",
    "augmented_images = []\n",
    "\n",
    "for i in range(augmentation_factor):\n",
    "    train_subset = Subset(data, train_data.indices)\n",
    "    train_subset.dataset = copy.deepcopy(train_subset.dataset)\n",
    "    train_subset.dataset.transform = train_transforms\n",
    "\n",
    "    augmented_images.append(train_subset)\n",
    "\n",
    "augmented_train_data = ConcatDataset(augmented_images)\n",
    "val_data.dataset.transform = val_test_transforms\n",
    "test_data.dataset.transform = val_test_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atvQ7LCX16hJ"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(augmented_train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_data,  batch_size=batch_size, shuffle=False)\n",
    "val_loader   = DataLoader(val_data,  batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQCYggMn18lX",
    "outputId": "b92809c9-46bc-4e29-a179-04605f7ac0c9"
   },
   "outputs": [],
   "source": [
    "print(data.class_to_idx)\n",
    "num_classes = len(data.class_to_idx)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHGP-Nqv4eEd",
    "outputId": "05d6e207-f602-4cb9-e489-db38210b76e9"
   },
   "outputs": [],
   "source": [
    "print(f\"Total images in dataset: {len(data)}\")\n",
    "print(f\"Train split size: {len(train_data)}\")\n",
    "print(f\"Validation split size: {len(val_data)}\")\n",
    "print(f\"Test split size: {len(test_data)}\")\n",
    "print(f\"Augmented train size: {len(augmented_train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2FFvCy4l-PK",
    "outputId": "3f15d8c0-571b-4fa3-bf68-e9f1abc61e86"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "val_labels = [val_data[i][1] for i in range(len(val_data))]\n",
    "test_labels = [test_data[i][1] for i in range(len(test_data))]\n",
    "\n",
    "val_class_counts = Counter(val_labels)\n",
    "test_class_counts = Counter(test_labels)\n",
    "\n",
    "print(\"Validation class distribution:\", val_class_counts)\n",
    "print(\"Test class distribution:\", test_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gs30_voomU3J",
    "outputId": "a0537330-14de-4d2a-fcb0-5425aab83425"
   },
   "outputs": [],
   "source": [
    "aug_labels = [augmented_train_data[i][1] for i in range(len(augmented_train_data))]\n",
    "aug_class_counts = Counter(aug_labels)\n",
    "\n",
    "print(\"Augmented Train class distribution:\", aug_class_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tnG-YSS5AKE"
   },
   "source": [
    "# **VGG 16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SzuVQMtt_YHY",
    "outputId": "3ee1aeda-692f-479d-cd69-29a244eb019d"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchvision.models import VGG16_Weights\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "\n",
    "model = models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "summary(model, (3, 224, 224))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDQgpgh7TnbE"
   },
   "source": [
    "## Tuned 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 766
    },
    "id": "djGCzG0X4_4m",
    "outputId": "d02ad1a3-1f2a-412e-c4dd-dd9439c499ee"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "model = models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "\n",
    "model.classifier[2] = nn.Dropout(p=0.4)\n",
    "model.classifier[5] = nn.Dropout(p=0.4)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "\n",
    "# Use GPU\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "#loss function and optimization\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "\n",
    "  #Training\n",
    "  model.train()\n",
    "  train_loss = 0.0\n",
    "  train_preds = [] #preds\n",
    "  actual_labels = [] #actual label\n",
    "\n",
    "\n",
    "  for inputs, labels in train_loader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss += loss.item()\n",
    "    train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "    actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "  train_acc = accuracy_score(actual_labels, train_preds)\n",
    "  avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "  #Validation\n",
    "  model.eval()\n",
    "  val_loss = 0.0\n",
    "  val_preds = []\n",
    "  val_labels = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      val_loss += loss.item()\n",
    "      val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "      val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "  val_acc = accuracy_score(val_labels, val_preds)\n",
    "  avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "  train_accuracies.append(train_acc)\n",
    "  val_accuracies.append(val_acc)\n",
    "\n",
    "\n",
    "  print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "          f\" accuracy: {train_acc:.4f} - loss: {avg_train_loss:.4f} \"\n",
    "          f\"- val_accuracy: {val_acc:.4f} - val_loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "train_acc_vgg = np.array(train_accuracies)\n",
    "val_acc_vgg = np.array(val_accuracies)\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"Average Training Accuracy over: {train_acc_vgg.mean():.4f}\")\n",
    "print(f\"Average Validation Accuracy over: {val_acc_vgg.mean():.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f'Testing Accuracy: {accuracy:.4f}')\n",
    "print(f'Testing Precision: {precision:.4f}')\n",
    "print(f'Testing Recall: {recall:.4f}')\n",
    "print(f'Testing F1 Score: {f1:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_acc_vgg, label='Training Accuracy', marker='o')\n",
    "plt.plot(val_acc_vgg, label='Validation Accuracy', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy over Epochs')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJ1FCG78TqxQ"
   },
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rLZyAwtKHiOk",
    "outputId": "c9ed6a7f-0e8a-4e67-d439-177fa2026dff"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "model = models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "\n",
    "model.classifier[2] = nn.Dropout(p=0.5)\n",
    "model.classifier[5] = nn.Dropout(p=0.5)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "#loss function and optimization\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "  #Training\n",
    "  model.train()\n",
    "  train_loss = 0.0\n",
    "  train_preds = [] #preds\n",
    "  actual_labels = [] #actual label\n",
    "\n",
    "\n",
    "  for inputs, labels in train_loader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss += loss.item()\n",
    "    train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "    actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "  train_acc = accuracy_score(actual_labels, train_preds)\n",
    "  avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "  #Validation\n",
    "  model.eval()\n",
    "  val_loss = 0.0\n",
    "  val_preds = []\n",
    "  val_labels = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      val_loss += loss.item()\n",
    "      val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "      val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "  val_acc = accuracy_score(val_labels, val_preds)\n",
    "  avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "  train_accuracies.append(train_acc)\n",
    "  val_accuracies.append(val_acc)\n",
    "\n",
    "\n",
    "  print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "          f\" accuracy: {train_acc:.4f} - loss: {avg_train_loss:.4f} \"\n",
    "          f\"- val_accuracy: {val_acc:.4f} - val_loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "train_acc_vgg = np.array(train_accuracies)\n",
    "val_acc_vgg = np.array(val_accuracies)\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"Average Training Accuracy over: {train_acc_vgg.mean():.4f}\")\n",
    "print(f\"Average Validation Accuracy over: {val_acc_vgg.mean():.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f'Testing Accuracy: {accuracy:.4f}')\n",
    "print(f'Testing Precision: {precision:.4f}')\n",
    "print(f'Testing Recall: {recall:.4f}')\n",
    "print(f'Testing F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "PadZWGgGHlDL",
    "outputId": "ced8eaef-9cf2-4ebc-f62d-e24f31ebb349"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_acc_vgg, label='Training Accuracy', marker='o')\n",
    "plt.plot(val_acc_vgg, label='Validation Accuracy', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy over Epochs')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftIXoVBoZRIb"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'best_vgg16_model_3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "bTFAvJQ5xr5r",
    "outputId": "84ca04ca-ddab-4c5f-d68e-7146b4919d81"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=test_loader.dataset.dataset.classes\n",
    ")\n",
    "disp.plot(xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Test Set\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "id": "MUrcR8etxzcZ",
    "outputId": "8a9d02b0-e4a4-4c29-e06e-33891d60ed6d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "fractions = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "results = []\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Full training set\n",
    "train_indices = list(range(len(train_data)))\n",
    "random.shuffle(train_indices)\n",
    "\n",
    "for frac in fractions:\n",
    "    print(f\"\\nTraining on {int(frac * 100)}% of the dataset...\")\n",
    "\n",
    "    split_len = int(frac * len(train_indices))\n",
    "    subset_indices = train_indices[:split_len]\n",
    "    train_subset = Subset(train_data, subset_indices)\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Model\n",
    "    model = models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "    model.classifier[2] = nn.Dropout(0.5)\n",
    "    model.classifier[5] = nn.Dropout(0.5)\n",
    "    model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)\n",
    "\n",
    "    # Train\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    #testing\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    results.append(acc)\n",
    "    print(f\"Test Accuracy with {int(frac*100)}% data: {acc:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot([int(f*100) for f in fractions], results, marker='o')\n",
    "plt.xlabel(\"Training Dataset Size (%)\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Test Accuracy vs Dataset Size\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUoMkLUCVEtI"
   },
   "source": [
    "## Tuned 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0PyxSiWsIHor",
    "outputId": "17422c51-56c6-4b8d-f2e3-d69bfa87ad17"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "model = models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "\n",
    "model.classifier[2] = nn.Dropout(p=0.6)\n",
    "model.classifier[5] = nn.Dropout(p=0.6)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "\n",
    "# Use GPU\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "#loss function and optimization\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "\n",
    "\n",
    "    #Training\n",
    "  model.train()\n",
    "  train_loss = 0.0\n",
    "  train_preds = [] #preds\n",
    "  actual_labels = [] #actual label\n",
    "\n",
    "\n",
    "  for inputs, labels in train_loader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss += loss.item()\n",
    "    train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "    actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "  train_acc = accuracy_score(actual_labels, train_preds)\n",
    "  avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "  #Validation\n",
    "  model.eval()\n",
    "  val_loss = 0.0\n",
    "  val_preds = []\n",
    "  val_labels = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      val_loss += loss.item()\n",
    "      val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "      val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "  val_acc = accuracy_score(val_labels, val_preds)\n",
    "  avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "  train_accuracies.append(train_acc)\n",
    "  val_accuracies.append(val_acc)\n",
    "\n",
    "\n",
    "  print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "          f\" accuracy: {train_acc:.4f} - loss: {avg_train_loss:.4f} \"\n",
    "          f\"- val_accuracy: {val_acc:.4f} - val_loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "train_acc_vgg = np.array(train_accuracies)\n",
    "val_acc_vgg = np.array(val_accuracies)\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"Average Training Accuracy over: {train_acc_vgg.mean():.4f}\")\n",
    "print(f\"Average Validation Accuracy over: {val_acc_vgg.mean():.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f'Testing Accuracy: {accuracy:.4f}')\n",
    "print(f'Testing Precision: {precision:.4f}')\n",
    "print(f'Testing Recall: {recall:.4f}')\n",
    "print(f'Testing F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "FalX3xZFafXE",
    "outputId": "b07f5abe-f101-49d5-ab38-68b2a89a5bcb"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_acc_vgg, label='Training Accuracy', marker='o')\n",
    "plt.plot(val_acc_vgg, label='Validation Accuracy', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy over Epochs')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGwoCizfu2Dv"
   },
   "source": [
    "# **Resnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qA9IqKRxABAn",
    "outputId": "8516e713-28a4-449c-a402-6b683867e809"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "summary(model, (3, 224, 224))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzQjjCUaiIZY"
   },
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0z8HY2QgrZV",
    "outputId": "a0a521d1-a1a1-4fb2-b6a8-c2410c0bd5b9"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet18_Weights\n",
    "import time\n",
    "\n",
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_preds = [] #preds\n",
    "    actual_labels = [] #actual label\n",
    "\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "        actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(actual_labels, train_preds)\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    #Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "          f\" accuracy: {train_acc:.4f} - loss: {avg_train_loss:.4f} \"\n",
    "          f\"- val_accuracy: {val_acc:.4f} - val_loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "train_acc_resnet = np.array(train_accuracies)\n",
    "val_acc_resnet = np.array(val_accuracies)\n",
    "\n",
    "\n",
    "print(f\"Average Training Accuracy over: {train_acc_resnet.mean():.4f}\")\n",
    "print(f\"Average Validation Accuracy over: {val_acc_resnet.mean():.4f}\")\n",
    "\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f'Testing Accuracy: {accuracy:.4f}')\n",
    "print(f'Testing Precision: {precision:.4f}')\n",
    "print(f'Testing Recall: {recall:.4f}')\n",
    "print(f'Testing F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMuVCaVzhEeW"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'best_ResNet_model_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "s3_y9r6dhDa0",
    "outputId": "e7c9ade8-3125-43f9-b81c-5ee218e97428"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_acc_resnet, label='Training Accuracy', marker='o')\n",
    "plt.plot(val_acc_resnet, label='Validation Accuracy', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy over Epochs')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "oSft6Sv_iOcK",
    "outputId": "bb93a983-7222-436d-f74b-49e124927da7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=test_loader.dataset.dataset.classes\n",
    ")\n",
    "disp.plot(xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Test Set\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "id": "ERyuB-4-iY0a",
    "outputId": "39d33e06-2efd-4661-bf58-30cc6a43910d"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Parameters\n",
    "fractions = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "results = []\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Shuffle training indices\n",
    "train_indices = list(range(len(train_data)))\n",
    "random.shuffle(train_indices)\n",
    "\n",
    "for frac in fractions:\n",
    "    print(f\"\\nTraining on {int(frac * 100)}% of the dataset...\")\n",
    "\n",
    "    # Prepare subset\n",
    "    split_len = int(frac * len(train_indices))\n",
    "    subset_indices = train_indices[:split_len]\n",
    "    train_subset = Subset(train_data, subset_indices)\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    #model\n",
    "    model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Testing\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    results.append(acc)\n",
    "    print(f\"Test Accuracy with {int(frac * 100)}% data: {acc:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot([int(f*100) for f in fractions], results, marker='o')\n",
    "plt.xlabel(\"Training Dataset Size (%)\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"ResNet18 - Test Accuracy vs Dataset Size\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGa9Mu2riUy2"
   },
   "source": [
    "## Tuned Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7-PLDo7kSck",
    "outputId": "0d5273bc-8a53-4623-b5c0-f47e408072dd"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet18_Weights\n",
    "import time\n",
    "\n",
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(model.fc.in_features, num_classes)\n",
    ")\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "start_time = time.time()\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_preds = [] #preds\n",
    "    actual_labels = [] #actual label\n",
    "\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "        actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(actual_labels, train_preds)\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    #Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "          f\" accuracy: {train_acc:.4f} - loss: {avg_train_loss:.4f} \"\n",
    "          f\"- val_accuracy: {val_acc:.4f} - val_loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "train_acc_resnet = np.array(train_accuracies)\n",
    "val_acc_resnet = np.array(val_accuracies)\n",
    "\n",
    "print(f\"Average Training Accuracy over: {train_acc_resnet.mean():.4f}\")\n",
    "print(f\"Average Validation Accuracy over: {val_acc_resnet.mean():.4f}\")\n",
    "\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f'Testing Accuracy: {accuracy:.4f}')\n",
    "print(f'Testing Precision: {precision:.4f}')\n",
    "print(f'Testing Recall: {recall:.4f}')\n",
    "print(f'Testing F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "XV_FgDP5kXDW",
    "outputId": "6337a232-2e97-4cda-8509-01ff2aeeb8d5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_acc_resnet, label='Training Accuracy', marker='o')\n",
    "plt.plot(val_acc_resnet, label='Validation Accuracy', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy over Epochs')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rke11ene65AF"
   },
   "source": [
    "## Tune model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GeeB5cLK9D7J",
    "outputId": "1d56dd2b-82e9-4440-9fc6-bc5a641179a2"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(model.fc.in_features, num_classes)\n",
    ")\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "train_accuracies_1 = []\n",
    "val_accuracies_1 = []\n",
    "\n",
    "num_epochs = 17\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_preds = [] #preds\n",
    "    actual_labels = [] #actual label\n",
    "\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "        actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(actual_labels, train_preds)\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    #Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    train_accuracies_1.append(train_acc)\n",
    "    val_accuracies_1.append(val_acc)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "          f\" accuracy: {train_acc:.4f} - loss: {avg_train_loss:.4f} \"\n",
    "          f\"- val_accuracy: {val_acc:.4f} - val_loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "train_acc_resnet = np.array(train_accuracies_1)\n",
    "val_acc_resnet = np.array(val_accuracies_1)\n",
    "\n",
    "print(f\"Average Training Accuracy over: {train_acc_resnet.mean():.4f}\")\n",
    "print(f\"Average Validation Accuracy over: {val_acc_resnet.mean():.4f}\")\n",
    "\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f'Testing Accuracy: {accuracy:.4f}')\n",
    "print(f'Testing Precision: {precision:.4f}')\n",
    "print(f'Testing Recall: {recall:.4f}')\n",
    "print(f'Testing F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "mVkDAyvm9oBo",
    "outputId": "3e1e0f34-c4f5-410f-a151-ec04d1dfe7ce"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_acc_resnet, label='Training Accuracy', marker='o')\n",
    "plt.plot(val_acc_resnet, label='Validation Accuracy', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy over Epochs')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2i0mYSteIGZB"
   },
   "source": [
    "# **Dense Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OY8wU1eoSdCP",
    "outputId": "7cef49ee-55d6-4143-d471-7264a1252b13"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision.models import DenseNet121_Weights\n",
    "from torchinfo import summary\n",
    "\n",
    "model = models.densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "summary(model, input_size=(1, 3, 224, 224))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GskqufDtLj34"
   },
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IYNtcankThtu",
    "outputId": "147e3bc2-0979-42e5-f566-8af6f0173c0c"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import DenseNet121_Weights\n",
    "import time\n",
    "\n",
    "model = models.densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(model.classifier.in_features, num_classes)\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.01)\n",
    "\n",
    "# Track accuracy\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "start_time = time.time()\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    actual_labels = []\n",
    "\n",
    "    #training\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "        actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(actual_labels, train_preds)\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "          f\"accuracy: {train_acc:.4f} - loss: {avg_train_loss:.4f} \"\n",
    "          f\"- val_accuracy: {val_acc:.4f} - val_loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Final results\n",
    "train_acc_arr = np.array(train_accuracies)\n",
    "val_acc_arr = np.array(val_accuracies)\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"Average Training Accuracy: {train_acc_arr.mean():.4f}\")\n",
    "print(f\"Average Validation Accuracy: {val_acc_arr.mean():.4f}\")\n",
    "\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f'Testing Accuracy: {accuracy:.4f}')\n",
    "print(f'Testing Precision: {precision:.4f}')\n",
    "print(f'Testing Recall: {recall:.4f}')\n",
    "print(f'Testing F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "Pge-9FxoTwF0",
    "outputId": "ccb9040d-2256-4180-8504-3682b4c50af3"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=test_loader.dataset.dataset.classes\n",
    ")\n",
    "disp.plot(xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Test Set\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "WTMZbo4Z_v14",
    "outputId": "9485e67e-f56a-4a94-a069-e24ecb115101"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_acc_arr, label='Training Accuracy', marker='o')\n",
    "plt.plot(val_acc_arr, label='Validation Accuracy', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy over Epochs')\n",
    "plt.ylim(0, 1)  # Set y-axis from 0 to 1\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tc7Cv4OH_zgq"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'best_DenseNet_model_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "id": "C874473aKO99",
    "outputId": "20224f41-3aa6-4d07-887b-bf1f64f54149"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Parameters\n",
    "fractions = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "results = []\n",
    "\n",
    "# Fix random seed\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Shuffle indices of the full train set\n",
    "train_indices = list(range(len(train_data)))\n",
    "random.shuffle(train_indices)\n",
    "\n",
    "for frac in fractions:\n",
    "    print(f\"\\nTraining on {int(frac * 100)}% of the dataset...\")\n",
    "\n",
    "    subset_len = int(frac * len(train_indices))\n",
    "    subset_indices = train_indices[:subset_len]\n",
    "    train_subset = Subset(train_data, subset_indices)\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Model\n",
    "    model = densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(model.classifier.in_features, num_classes)\n",
    "    )\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Testing\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    results.append(acc)\n",
    "    print(f\"Test Accuracy with {int(frac * 100)}% data: {acc:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot([int(f*100) for f in fractions], results, marker='o')\n",
    "plt.xlabel(\"Training Dataset Size (%)\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"DenseNet121 - Test Accuracy vs Dataset Size\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBxwVySOKalP"
   },
   "source": [
    "## Tune 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eRWZp-gRSteu",
    "outputId": "d6bed3c4-192b-44a7-dd8a-732a88999331"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import DenseNet121_Weights\n",
    "import time\n",
    "\n",
    "model = models.densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(model.classifier.in_features, num_classes)\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "# Track accuracy\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "start_time = time.time()\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "# Training\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    actual_labels = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "        actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(actual_labels, train_preds)\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "          f\"accuracy: {train_acc:.4f} - loss: {avg_train_loss:.4f} \"\n",
    "          f\"- val_accuracy: {val_acc:.4f} - val_loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Final results\n",
    "train_acc_arr = np.array(train_accuracies)\n",
    "val_acc_arr = np.array(val_accuracies)\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"Average Training Accuracy: {train_acc_arr.mean():.4f}\")\n",
    "print(f\"Average Validation Accuracy: {val_acc_arr.mean():.4f}\")\n",
    "\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f'Testing Accuracy: {accuracy:.4f}')\n",
    "print(f'Testing Precision: {precision:.4f}')\n",
    "print(f'Testing Recall: {recall:.4f}')\n",
    "print(f'Testing F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "esQ0uOsFTSSY",
    "outputId": "b1e50f3b-c44d-41c9-b919-b8a550113f3d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_acc_arr, label='Training Accuracy', marker='o')\n",
    "plt.plot(val_acc_arr, label='Validation Accuracy', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy over Epochs')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHMZNzU4xIsL"
   },
   "source": [
    "## Tuned 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dterhP3NTMi6",
    "outputId": "dfa4d7fb-443a-4dab-9345-51fbe0a822ac"
   },
   "outputs": [],
   "source": [
    "model = models.densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(model.classifier.in_features, num_classes)\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay= 0.001)\n",
    "\n",
    "# Track accuracy\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "start_time = time.time()\n",
    "num_epochs = 10\n",
    "\n",
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    actual_labels = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "        actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(actual_labels, train_preds)\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "          f\"accuracy: {train_acc:.4f} - loss: {avg_train_loss:.4f} \"\n",
    "          f\"- val_accuracy: {val_acc:.4f} - val_loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Final results\n",
    "train_acc_arr = np.array(train_accuracies)\n",
    "val_acc_arr = np.array(val_accuracies)\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"Average Training Accuracy: {train_acc_arr.mean():.4f}\")\n",
    "print(f\"Average Validation Accuracy: {val_acc_arr.mean():.4f}\")\n",
    "\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f'Testing Accuracy: {accuracy:.4f}')\n",
    "print(f'Testing Precision: {precision:.4f}')\n",
    "print(f'Testing Recall: {recall:.4f}')\n",
    "print(f'Testing F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "HFf4sdlhTTol",
    "outputId": "3ede0b89-a565-402b-ea76-2f2a7304ca1f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_acc_arr, label='Training Accuracy', marker='o')\n",
    "plt.plot(val_acc_arr, label='Validation Accuracy', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy over Epochs')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWUFS27DBeiF"
   },
   "source": [
    "# GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AvA2itsZDeDn",
    "outputId": "7a45165d-b135-46a8-eab4-51154eeac076"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import GoogLeNet_Weights\n",
    "\n",
    "model = models.googlenet(weights=GoogLeNet_Weights.DEFAULT)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "summary(model, (3, 224, 224))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSB7GXhfKzNX"
   },
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Am_jLBexBhyo",
    "outputId": "10cd5723-b6d8-4ee3-ea07-f27bc649e284"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.models import GoogLeNet_Weights\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "model = models.googlenet(weights=GoogLeNet_Weights.DEFAULT)\n",
    "model.fc = nn.Sequential(nn.Dropout(p=0.5),nn.Linear(model.fc.in_features, num_classes))\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay = 0.001)\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "start_time = time.time()\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    actual_labels = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "        actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(actual_labels, train_preds)\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "          f\" accuracy: {train_acc:.4f} - loss: {avg_train_loss:.4f} \"\n",
    "          f\"- val_accuracy: {val_acc:.4f} - val_loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "train_acc_google = np.array(train_accuracies)\n",
    "val_acc_google = np.array(val_accuracies)\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Average Training Accuracy over: {train_acc_google.mean():.4f}\")\n",
    "print(f\"Average Validation Accuracy over: {val_acc_google.mean():.4f}\")\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f'Testing Accuracy: {accuracy:.4f}')\n",
    "print(f'Testing Precision: {precision:.4f}')\n",
    "print(f'Testing Recall: {recall:.4f}')\n",
    "print(f'Testing F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "8jxuHuYyEMZf",
    "outputId": "20192af4-9194-4705-d39d-94524b1b1667"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_accuracies, label='Training Accuracy', marker='o')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy over Epochs')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-o4YwY_KNhZ"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'best_GoogLeNet_model_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "id": "vtvU_KA3uNXh",
    "outputId": "e931def7-fbcd-421e-bd6c-903df10b6ea6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Parameters\n",
    "fractions = [0.2, 0.4,0.6, 0.8, 1.0]\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "results = []\n",
    "\n",
    "# Fix random seed\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "for frac in fractions:\n",
    "    print(f\"\\nTraining on {int(frac * 100)}% of the dataset...\")\n",
    "\n",
    "    train_indices = list(range(len(augmented_train_data)))\n",
    "    random.shuffle(train_indices)\n",
    "    subset_len = int(frac * len(train_indices))\n",
    "    subset_indices = train_indices[:subset_len]\n",
    "    train_subset = Subset(augmented_train_data, subset_indices)\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Model\n",
    "    model = models.googlenet(weights=GoogLeNet_Weights.DEFAULT)\n",
    "    model.fc = nn.Sequential(nn.Dropout(p=0.5),nn.Linear(model.fc.in_features, num_classes))\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Testing\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    results.append(acc)\n",
    "    print(f\"Test Accuracy with {int(frac * 100)}% data: {acc:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot([int(f*100) for f in fractions], results, marker='o')\n",
    "plt.xlabel(\"Training Dataset Size (%)\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"GoogLeNet - Test Accuracy vs Dataset Size\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "5w7lSw3v38kD",
    "outputId": "70fab264-4ab6-4fec-d47e-d74f210c2e09"
   },
   "outputs": [],
   "source": [
    "dataset_sizes = [20, 40, 60, 80, 100]\n",
    "test_accuracies = [0.9929, 0.9982, 0.9965, 0.9982, 0.9911]\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(dataset_sizes, test_accuracies, marker='o', linestyle='-', color='royalblue')\n",
    "\n",
    "plt.xlabel(\"Training Dataset Size (%)\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Test Accuracy vs Dataset Size GoogLeNet)\")\n",
    "plt.ylim(0.9, 1)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "ifv0h_8lKjdT",
    "outputId": "0b05cba9-9d27-4d43-ed09-b17f28ac8a82"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=test_loader.dataset.dataset.classes\n",
    ")\n",
    "disp.plot(xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Test Set\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrX_v5OdLQPt"
   },
   "source": [
    "## Tune 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7azJRyhXLRef",
    "outputId": "a264cf34-63f5-49f8-ae46-f35d87adb53f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.models import GoogLeNet_Weights\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "model = models.googlenet(weights=GoogLeNet_Weights.DEFAULT)\n",
    "model.fc = nn.Sequential(nn.Dropout(p=0.5),nn.Linear(model.fc.in_features, num_classes))\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 0.001)\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "start_time = time.time()\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    actual_labels = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "        actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(actual_labels, train_preds)\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "          f\" accuracy: {train_acc:.4f} - loss: {avg_train_loss:.4f} \"\n",
    "          f\"- val_accuracy: {val_acc:.4f} - val_loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "train_acc_google = np.array(train_accuracies)\n",
    "val_acc_google = np.array(val_accuracies)\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Average Training Accuracy over: {train_acc_google.mean():.4f}\")\n",
    "print(f\"Average Validation Accuracy over: {val_acc_google.mean():.4f}\")\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f'Testing Accuracy: {accuracy:.4f}')\n",
    "print(f'Testing Precision: {precision:.4f}')\n",
    "print(f'Testing Recall: {recall:.4f}')\n",
    "print(f'Testing F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "P9l1cPb4MSA8",
    "outputId": "7f28a27a-13c7-4814-b20b-2ec54c343863"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_accuracies, label='Training Accuracy', marker='o')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy over Epochs')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_NneimYOmM-"
   },
   "source": [
    "## Tune 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQfq4XvOOng4",
    "outputId": "ebf1f2c8-034c-4590-fb97-dab1fe601e99"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.models import GoogLeNet_Weights\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "model = models.googlenet(weights=GoogLeNet_Weights.DEFAULT)\n",
    "model.fc = nn.Sequential(nn.Dropout(p=0.5),nn.Linear(model.fc.in_features, num_classes))\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0007, weight_decay = 0.00001)\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "start_time = time.time()\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    actual_labels = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "        actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(actual_labels, train_preds)\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "          f\" accuracy: {train_acc:.4f} - loss: {avg_train_loss:.4f} \"\n",
    "          f\"- val_accuracy: {val_acc:.4f} - val_loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "train_acc_google = np.array(train_accuracies)\n",
    "val_acc_google = np.array(val_accuracies)\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Average Training Accuracy over: {train_acc_google.mean():.4f}\")\n",
    "print(f\"Average Validation Accuracy over: {val_acc_google.mean():.4f}\")\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f'Testing Accuracy: {accuracy:.4f}')\n",
    "print(f'Testing Precision: {precision:.4f}')\n",
    "print(f'Testing Recall: {recall:.4f}')\n",
    "print(f'Testing F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "VSVd1v4TO0WC",
    "outputId": "1245a141-a585-4ef2-fe50-94defe4a5134"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_accuracies, label='Training Accuracy', marker='o')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy over Epochs')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4cDfZQMnA8E"
   },
   "source": [
    "#**Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "tVguSo69tuhZ",
    "outputId": "12e1775b-5e67-40b3-a973-7cb8a6b7b42a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_names = ['VGG16', 'ResNet18', 'DenseNet121', 'GoogLeNet']\n",
    "val_accuracies = [0.9565, 0.9813, 0.9689, 0.973]\n",
    "training_accuracy = [0.9426, 0.9888, 0.981, 0.9859]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars1 = plt.bar(x - width/2, val_accuracies, width, label='Validation Accuracy')\n",
    "bars2 = plt.bar(x + width/2, training_accuracy, width, label='Training Accuracy')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(x, model_names)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation vs Training Accuracy for Best Models\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "AEybZ7Rou-m6",
    "outputId": "f2b0e8ad-187f-4ad5-8f53-63d1e62c61ae"
   },
   "outputs": [],
   "source": [
    "#vgg16 graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_names = ['1st Combination', '2nd combination', '3rd combination']\n",
    "val_accuracies = [0.9565, 0.7706, 0.9685]\n",
    "training_accuracy = [0.9426, 0.7618, 0.9124]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars1 = plt.bar(x - width/2, val_accuracies, width, label='Validation Accuracy')\n",
    "bars2 = plt.bar(x + width/2, training_accuracy, width, label='Train Accuracy')\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(x, model_names)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation vs Training Accuracy for VGG16\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "OGrFXaH9v_NY",
    "outputId": "1dd0bed6-2e5c-4d60-9b06-acb00eae6adc"
   },
   "outputs": [],
   "source": [
    "#vgg16 graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_names = ['1st Combination', '2nd combination', '3rd combination']\n",
    "val_accuracies = [0.9689, 0.9536, 0.9393]\n",
    "training_accuracy = [0.981, 0.9731, 0.9789]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars1 = plt.bar(x - width/2, val_accuracies, width, label='Validation Accuracy')\n",
    "bars2 = plt.bar(x + width/2, training_accuracy, width, label='Train Accuracy')\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(x, model_names)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation vs Training Accuracy for DenseNet\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "hHhEWACDwYD6",
    "outputId": "97dd40bf-2b8c-4609-9fa1-e7f472205638"
   },
   "outputs": [],
   "source": [
    "#ResNet graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_names = ['1st Combination', '2nd combination', '3rd combination']\n",
    "val_accuracies = [0.9813, 0.925, 0.946]\n",
    "training_accuracy = [0.9888, 0.9831, 0.9817]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars1 = plt.bar(x - width/2, val_accuracies, width, label='Validation Accuracy')\n",
    "bars2 = plt.bar(x + width/2, training_accuracy, width, label='Train Accuracy')\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(x, model_names)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation vs Training Accuracy for ResNet\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "r5H3ld0Nwnzs",
    "outputId": "0af571f1-8f04-4eda-faff-dc00659174c9"
   },
   "outputs": [],
   "source": [
    "#GoogLeNet graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_names = ['1st Combination', '2nd combination', '3rd combination']\n",
    "val_accuracies = [0.973, 0.9291, 0.9661]\n",
    "training_accuracy = [0.9859, 0.9785, 0.9862]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars1 = plt.bar(x - width/2, val_accuracies, width, label='Validation Accuracy')\n",
    "bars2 = plt.bar(x + width/2, training_accuracy, width, label='Train Accuracy')\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(x, model_names)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation vs Training Accuracy for GoogLeNet\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNAkZC1_xHcc"
   },
   "source": [
    "# Interface For Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_5DRVCqxKAn",
    "outputId": "d8585f56-e95e-4625-faef-28df135870bc"
   },
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vsd1oa9yz5kk"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "L3PfLJwj4ox1",
    "outputId": "90544afd-32fb-4c2d-c809-896626206c2f"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import GoogLeNet_Weights\n",
    "from PIL import Image\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "MODEL_PATH = \"best_GoogLeNet_model_1.pth\"\n",
    "NUM_CLASSES = 4\n",
    "CLASS_NAMES = ['Cloudy', 'Desert', 'Green Area', 'Water']\n",
    "\n",
    "# --- MODEL WRAPPER ---\n",
    "class GoogLeNetClassifier:\n",
    "    def __init__(self, model_path, num_classes):\n",
    "        self.model = models.googlenet(weights=GoogLeNet_Weights.DEFAULT)\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(self.model.fc.in_features, num_classes)\n",
    "        )\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")))\n",
    "        self.model.eval()\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def predict(self, image):\n",
    "        img_tensor = self.transform(image).unsqueeze(0)  # Shape: (1, 3, 224, 224)\n",
    "        with torch.no_grad():\n",
    "            output = self.model(img_tensor)\n",
    "            probs = F.softmax(output, dim=1)\n",
    "            class_idx = torch.argmax(probs, dim=1).item()\n",
    "            confidence = probs[0][class_idx].item()\n",
    "            return f\"Predicted class: {CLASS_NAMES[class_idx]} (Confidence: {confidence:.2f})\"\n",
    "\n",
    "# --- INIT ---\n",
    "classifier = GoogLeNetClassifier(MODEL_PATH, NUM_CLASSES)\n",
    "\n",
    "# --- GRADIO UI ---\n",
    "interface = gr.Interface(\n",
    "    fn=classifier.predict,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"GoogLeNet Satellite Image Classifier\",\n",
    "    description=\"Upload a satellite image to classify it into one of four categories: Cloudy, Desert, Green Area, or Water.\"\n",
    ")\n",
    "\n",
    "interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8CYz-YA4pkx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
